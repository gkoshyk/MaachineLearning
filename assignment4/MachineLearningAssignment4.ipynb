{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning Assignment 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Text classification is one of the fundamental tasks in data mining and machine learning. In this assignment,\n",
    "# you will get an opportunity to train classifiers to recognize the topics represented by documents.\n",
    "# You will use the 20 Newsgroups dataset. It contains newsgroup documents relating to 20 different topics. \n",
    "# It can be downloaded from: http://qwone.com/~jason/20Newsgroups/\n",
    "# There are 3 different versions available for download. It is recommended that you use the \"bydate\" version.\n",
    "# It has documents split up into training and testing sets.\n",
    "# You can limit yourself to any 5 topics that are most interesting to you. \n",
    "# The topics can be inferred from the names of the directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Install python 2.7 \n",
    "\n",
    "# Install jupyter command\n",
    "#    pip install jupyter\n",
    "\n",
    "# Install latest dev version of sklearn command\n",
    "#    pip install git+git://github.com/scikit-learn/scikit-learn.git\n",
    "\n",
    "# Start jupyter command \n",
    "#    ipython notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "from time import time\n",
    "# Module to import the fetch_20newsgroups data\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The five categories of docs which we are going to use to train the model.\n",
    "categories = ['alt.atheism', 'soc.religion.christian','comp.graphics', 'sci.med','talk.politics.mideast']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'sci.med',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.mideast']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_train = fetch_20newsgroups(subset='train',categories=categories, shuffle=True, random_state=42)\n",
    "#The topic classes chosen\n",
    "twenty_train.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting features from text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2821, 42857)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text preprocessing, tokenizing and filtering of stopwords are included in a high level component \n",
    "# that is able to build a dictionary of features and transform documents to feature vectors:\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(twenty_train.data)\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2821, 42857)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Both tf and tfâ€“idf can be computed as follows:\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_counts)\n",
    "X_train_tf = tf_transformer.transform(X_train_counts)\n",
    "X_train_tf.shape\n",
    "\n",
    "# we firstly use the fit(..) method to fit our estimator to the data and secondly the transform(..) \n",
    "# method to transform our count-matrix to a tf-idf representation. \n",
    "# These two steps can be combined to achieve the same end result faster by skipping redundant processing. \n",
    "# This is done through using the fit_transform(..) method as shown below, and as mentioned in the note \n",
    "# in the previous section:\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the required machine learning modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn import tree\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a pipeline and training the classifier and Evaluation of the performance on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier_map = {\"Multinomial Naive Bayes Algorithm\" : MultinomialNB(),\n",
    "                \"Stochastic Gradient Descent Algorithm\" : SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, n_iter=5, random_state=42),\n",
    "                \"Support Vector Classifier Algorithm\" : LinearSVC(penalty=\"l1\", dual=False, tol=1e-3),\n",
    "                \"Perceptron Algorithm\" :Perceptron(n_iter=50),\n",
    "                \"Passive Aggressive Classifier Algorithm\": PassiveAggressiveClassifier(n_iter=50),\n",
    "                \"K nearest neighbor Algorithm\": KNeighborsClassifier(n_neighbors=10),\n",
    "                \"Random Forest Algorithm\" : RandomForestClassifier(n_estimators=100),\n",
    "                \"Nearest Centroid Algorithm\" : NearestCentroid(),\n",
    "                \"Decision Tree Algorithm\" : tree.DecisionTreeClassifier()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy after running Stochastic Gradient Descent Algorithm is 0.908413\n",
      "\n",
      "The table metrics for Stochastic Gradient Descent Algorithm is \n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.92      0.77      0.84       319\n",
      "         comp.graphics       0.85      0.98      0.91       389\n",
      "               sci.med       0.95      0.87      0.91       396\n",
      "soc.religion.christian       0.88      0.95      0.91       398\n",
      " talk.politics.mideast       0.96      0.95      0.95       376\n",
      "\n",
      "           avg / total       0.91      0.91      0.91      1878\n",
      "\n",
      "****************************************************************\n",
      "The accuracy after running Support Vector Classifier Algorithm is 0.885517\n",
      "\n",
      "The table metrics for Support Vector Classifier Algorithm is \n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.83      0.77      0.80       319\n",
      "         comp.graphics       0.88      0.96      0.92       389\n",
      "               sci.med       0.90      0.89      0.90       396\n",
      "soc.religion.christian       0.85      0.93      0.89       398\n",
      " talk.politics.mideast       0.98      0.85      0.91       376\n",
      "\n",
      "           avg / total       0.89      0.89      0.88      1878\n",
      "\n",
      "****************************************************************\n",
      "The accuracy after running Multinomial Naive Bayes Algorithm is 0.849308\n",
      "\n",
      "The table metrics for Multinomial Naive Bayes Algorithm is \n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.97      0.59      0.73       319\n",
      "         comp.graphics       0.97      0.89      0.93       389\n",
      "               sci.med       0.97      0.82      0.89       396\n",
      "soc.religion.christian       0.63      0.99      0.77       398\n",
      " talk.politics.mideast       0.95      0.92      0.93       376\n",
      "\n",
      "           avg / total       0.89      0.85      0.85      1878\n",
      "\n",
      "****************************************************************\n",
      "The accuracy after running Random Forest Algorithm is 0.823216\n",
      "\n",
      "The table metrics for Random Forest Algorithm is \n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.88      0.66      0.76       319\n",
      "         comp.graphics       0.70      0.97      0.81       389\n",
      "               sci.med       0.86      0.69      0.77       396\n",
      "soc.religion.christian       0.82      0.93      0.87       398\n",
      " talk.politics.mideast       0.96      0.83      0.89       376\n",
      "\n",
      "           avg / total       0.84      0.82      0.82      1878\n",
      "\n",
      "****************************************************************\n",
      "The accuracy after running Passive Aggressive Classifier Algorithm is 0.923855\n",
      "\n",
      "The table metrics for Passive Aggressive Classifier Algorithm is \n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.90      0.84      0.87       319\n",
      "         comp.graphics       0.92      0.97      0.94       389\n",
      "               sci.med       0.95      0.91      0.93       396\n",
      "soc.religion.christian       0.89      0.97      0.92       398\n",
      " talk.politics.mideast       0.97      0.91      0.94       376\n",
      "\n",
      "           avg / total       0.93      0.92      0.92      1878\n",
      "\n",
      "****************************************************************\n",
      "The accuracy after running Decision Tree Algorithm is 0.685304\n",
      "\n",
      "The table metrics for Decision Tree Algorithm is \n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.59      0.67      0.63       319\n",
      "         comp.graphics       0.71      0.78      0.74       389\n",
      "               sci.med       0.59      0.54      0.56       396\n",
      "soc.religion.christian       0.74      0.77      0.75       398\n",
      " talk.politics.mideast       0.83      0.66      0.73       376\n",
      "\n",
      "           avg / total       0.69      0.69      0.69      1878\n",
      "\n",
      "****************************************************************\n",
      "The accuracy after running Nearest Centroid Algorithm is 0.722577\n",
      "\n",
      "The table metrics for Nearest Centroid Algorithm is \n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.87      0.56      0.68       319\n",
      "         comp.graphics       0.56      0.93      0.70       389\n",
      "               sci.med       0.81      0.58      0.68       396\n",
      "soc.religion.christian       0.68      0.77      0.72       398\n",
      " talk.politics.mideast       0.94      0.74      0.83       376\n",
      "\n",
      "           avg / total       0.77      0.72      0.72      1878\n",
      "\n",
      "****************************************************************\n",
      "The accuracy after running K nearest neighbor Algorithm is 0.748669\n",
      "\n",
      "The table metrics for K nearest neighbor Algorithm is \n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.56      0.83      0.67       319\n",
      "         comp.graphics       0.93      0.77      0.84       389\n",
      "               sci.med       0.89      0.51      0.65       396\n",
      "soc.religion.christian       0.74      0.83      0.78       398\n",
      " talk.politics.mideast       0.76      0.82      0.79       376\n",
      "\n",
      "           avg / total       0.78      0.75      0.75      1878\n",
      "\n",
      "****************************************************************\n",
      "The accuracy after running Perceptron Algorithm is 0.897764\n",
      "\n",
      "The table metrics for Perceptron Algorithm is \n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.86      0.81      0.84       319\n",
      "         comp.graphics       0.93      0.94      0.93       389\n",
      "               sci.med       0.94      0.89      0.91       396\n",
      "soc.religion.christian       0.85      0.96      0.90       398\n",
      " talk.politics.mideast       0.92      0.86      0.89       376\n",
      "\n",
      "           avg / total       0.90      0.90      0.90      1878\n",
      "\n",
      "****************************************************************\n"
     ]
    }
   ],
   "source": [
    "twenty_test = fetch_20newsgroups(subset='test',categories=categories, shuffle=True, random_state=42)\n",
    "docs_test = twenty_test.data\n",
    "\n",
    "f = open('ReportOfRunningScript.txt','a')\n",
    "\n",
    "for classifier_name, classifier in classifier_map.iteritems():\n",
    "    text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', classifier),\n",
    "                    ])\n",
    "    text_clf = text_clf.fit(twenty_train.data, twenty_train.target)\n",
    "    predicted = text_clf.predict(docs_test)\n",
    "    \n",
    "    np.mean(predicted == twenty_test.target)\n",
    "    print(\"The accuracy after running %s is %f\\n\" %(classifier_name,np.mean(predicted == twenty_test.target)))\n",
    "    f.write(\"The accuracy after running %s is %f\\n\" %(classifier_name,np.mean(predicted == twenty_test.target)))\n",
    "    print(\"The table metrics for %s is \" %classifier_name)\n",
    "    f.write(\"The table metrics for %s is \" %classifier_name)\n",
    "    print(metrics.classification_report(twenty_test.target, predicted,target_names=twenty_test.target_names))    \n",
    "    f.write(metrics.classification_report(twenty_test.target, predicted,target_names=twenty_test.target_names))    \n",
    "    print(\"****************************************************************\")\n",
    "    f.write(\"****************************************************************\")    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
